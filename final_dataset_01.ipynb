{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data with release filter\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pydriller import RepositoryMining\n",
    "from radon.raw import analyze\n",
    "from radon.metrics import h_visit\n",
    "from radon.metrics import h_visit_ast\n",
    "from radon.complexity import sorted_results\n",
    "from pydriller.git_repository import GitRepository\n",
    "\n",
    "fields = ['CommitID','filename','token_count','change_type','loc','lloc','sloc','comments',\n",
    "          'multi','blank','code_comment','h1','h2','N1','N2','vocabulary','length',\n",
    "          'calculated_length','volume', 'difficulty','effort','time','bugs']\n",
    "# 'lines_added','lines_removed',\n",
    "repo_updated = \"/Users/sanika/Downloads/Master Thesis/repo_updated/pytest\"\n",
    "    \n",
    "gr = GitRepository(\"/Users/sanika/Downloads/Master Thesis/repo_updated/pytest\")\n",
    "# no_commits = gitrepo.total_commits() #total number of commits\n",
    "\n",
    "count = 0\n",
    "buggy_list = []\n",
    "\n",
    "with open('final_dataset_01.csv', 'w') as csvFile:\n",
    "    writer = csv.DictWriter(csvFile, fieldnames = fields)\n",
    "    writer.writeheader()\n",
    "    for commit in RepositoryMining(repo_updated,\n",
    "                                   only_modifications_with_file_types=['.py'] ).traverse_commits():\n",
    "        for modification in commit.modifications:\n",
    "            filename = modification.filename\n",
    "            hash_val = commit.hash\n",
    "            change_type = modification.change_type\n",
    "            token_count = modification.token_count\n",
    "#                 added = modification.added\n",
    "#                 removed = modification.removed\n",
    "            if filename.endswith(\".py\"):\n",
    "                #Get bug inducing commits in a list\n",
    "                commit1 = gr.get_commit(commit.hash)\n",
    "                buggy_commits = gr.get_commits_last_modified_lines(commit1) #get bug inducing commits\n",
    "                for x in buggy_commits:\n",
    "                    buggy_list.append(x)\n",
    "                #Calculate metrics for all commits\n",
    "                for r, d, f in os.walk(repo_updated):\n",
    "                    for file in f:\n",
    "                        if filename in file:\n",
    "                            file_path = os.path.join(r, file)\n",
    "                            with open(file_path) as f:\n",
    "                                content = f.read()\n",
    "                                file_analyze = analyze(content)\n",
    "                                code_n_comment = file_analyze.loc+file_analyze.comments\n",
    "                                file_ast = h_visit(content)\n",
    "                                data = [{'CommitID':(hash_val), \n",
    "                                         'filename':(file_path),\n",
    "                                     'token_count':(token_count),\n",
    "                                     'change_type':(change_type),\n",
    "#                                      'lines_added':(added),\n",
    "#                                      'lines_removed':(removed),\n",
    "                                     'loc':(file_analyze.loc),\n",
    "                                     'lloc':(file_analyze.lloc),\n",
    "                                     'sloc':(file_analyze.sloc),\n",
    "                                     'comments':(file_analyze.comments),\n",
    "                                     'multi':(file_analyze.multi),\n",
    "                                     'blank':(file_analyze.blank),\n",
    "                                     'code_comment':(code_n_comment),\n",
    "                                     'h1':(file_ast.total.h1),\n",
    "                                     'h2':(file_ast.total.h2),\n",
    "                                     'N1':(file_ast.total.N1),\n",
    "                                     'N2':(file_ast.total.N2),\n",
    "                                     'vocabulary':(file_ast.total.vocabulary),\n",
    "                                     'length':(file_ast.total.length),\n",
    "                                     'calculated_length':(file_ast.total.calculated_length),\n",
    "                                     'volume':(file_ast.total.volume),                     \n",
    "                                     'difficulty':(file_ast.total.difficulty),\n",
    "                                     'effort':(file_ast.total.effort),\n",
    "                                     'time':(file_ast.total.time),\n",
    "                                     'bugs':(file_ast.total.bugs),}]\n",
    "                                writer.writerows(data)  \n",
    "print(\"writing completed\")\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
