{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset_processed_01.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7205287713841368\n",
      "Precision: 0.5704379562043795\n",
      "Recall: 0.392713567839196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81      8880\n",
      "           1       0.57      0.39      0.47      3980\n",
      "\n",
      "    accuracy                           0.72     12860\n",
      "   macro avg       0.67      0.63      0.64     12860\n",
      "weighted avg       0.70      0.72      0.70     12860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fetch data and add headers\n",
    "filepath = 'python_01.csv'\n",
    "\n",
    "column = ['complexity','token_count','loc','lloc','sloc','comments',\n",
    "          'multi','blank','code_comment','h1','h2','N1','N2','vocabulary','length',\n",
    "          'calculated_length','volume', 'difficulty','effort','time','bugs','defect']\n",
    "df1 = pd.read_csv(filepath, index_col=False,usecols= column)\n",
    "\n",
    "X = df1.iloc[:,0:-1] #features\n",
    "y = df1.iloc[:,-1] #labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=None) \n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "#get accuracy, precision, recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test,predicted)\n",
    "precision_score = precision_score(y_test,predicted)\n",
    "recall_score = recall_score(y_test,predicted)\n",
    "print(\"Accuracy:\",accuracy_score)\n",
    "print(\"Precision:\",precision_score)\n",
    "print(\"Recall:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset_processed_02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7305598755832037\n",
      "Precision: 0.573790201382627\n",
      "Recall: 0.48255813953488375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      8904\n",
      "           1       0.57      0.48      0.52      3956\n",
      "\n",
      "    accuracy                           0.73     12860\n",
      "   macro avg       0.68      0.66      0.67     12860\n",
      "weighted avg       0.72      0.73      0.72     12860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fetch data and add headers\n",
    "column = ['complexity','token_count','loc','lloc','sloc','comments',\n",
    "          'multi','blank','code_comment','h1','h2','N1','N2','vocabulary','length',\n",
    "          'calculated_length','volume', 'difficulty','effort','time','bugs',\n",
    "          'change_type','added','removed','defect']\n",
    "filepath = 'python_02.csv'\n",
    "\n",
    "df2 = pd.read_csv(filepath, index_col=False, usecols = column)\n",
    "\n",
    "X = df2.iloc[:,0:-1] #features\n",
    "y = df2.iloc[:,-1] #labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=None) \n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "#get accuracy, precision, recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test,predicted)\n",
    "precision_score = precision_score(y_test,predicted)\n",
    "recall_score = recall_score(y_test,predicted)\n",
    "print(\"Accuracy:\",accuracy_score)\n",
    "print(\"Precision:\",precision_score)\n",
    "print(\"Recall:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset_processed_03.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8953343701399689\n",
      "Precision: 0.833807185319204\n",
      "Recall: 0.821074064647493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      8931\n",
      "           1       0.83      0.82      0.83      3929\n",
      "\n",
      "    accuracy                           0.90     12860\n",
      "   macro avg       0.88      0.87      0.88     12860\n",
      "weighted avg       0.89      0.90      0.90     12860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fetch data and add headers\n",
    "filepath = 'python_03.csv'\n",
    "column = ['complexity','token_count','loc','lloc','sloc','comments',\n",
    "          'multi','blank','code_comment','h1','h2','N1','N2','vocabulary','length',\n",
    "          'calculated_length','volume', 'difficulty','effort','time','bugs','change_type','added','removed',\n",
    "          'introspection','object_changes','code_generation','library_loading','defect']\n",
    "\n",
    "df3 = pd.read_csv(filepath, index_col=False, usecols = column)\n",
    "\n",
    "X = df3.iloc[:,0:-1] #features\n",
    "y = df3.iloc[:,-1] #labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=None) \n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "#get accuracy, precision, recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test,predicted)\n",
    "precision_score = precision_score(y_test,predicted)\n",
    "recall_score = recall_score(y_test,predicted)\n",
    "print(\"Accuracy:\",accuracy_score)\n",
    "print(\"Precision:\",precision_score)\n",
    "print(\"Recall:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## promise_CM1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8533333333333334\n",
      "Precision: 0.2857142857142857\n",
      "Recall: 0.46153846153846156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.89      0.92       137\n",
      "        True       0.29      0.46      0.35        13\n",
      "\n",
      "    accuracy                           0.85       150\n",
      "   macro avg       0.62      0.68      0.64       150\n",
      "weighted avg       0.89      0.85      0.87       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fetch data and add headers\n",
    "filepath = 'promise_CM1.csv'\n",
    "\n",
    "df4 = pd.read_csv(filepath,header = None)\n",
    "\n",
    "X = df4.iloc[:,0:-1] #features\n",
    "y = df4.iloc[:,-1] #labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=None) \n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "# clf = DecisionTreeClassifier(criterion=\"entropy\",max_depth=3)\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#get accuracy, precision, recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test,predicted)\n",
    "precision_score = precision_score(y_test,predicted)\n",
    "recall_score = recall_score(y_test,predicted)\n",
    "print(\"Accuracy:\",accuracy_score)\n",
    "print(\"Precision:\",precision_score)\n",
    "print(\"Recall:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## promise_KC3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "Precision: 0.16666666666666666\n",
      "Recall: 0.13333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.92      0.91       123\n",
      "        True       0.17      0.13      0.15        15\n",
      "\n",
      "    accuracy                           0.83       138\n",
      "   macro avg       0.53      0.53      0.53       138\n",
      "weighted avg       0.82      0.83      0.83       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fetch data and add headers\n",
    "filepath = 'promise_KC3.csv'\n",
    "\n",
    "df5 = pd.read_csv(filepath, header = None)\n",
    "\n",
    "X = df5.iloc[:,0:-1] #features\n",
    "y = df5.iloc[:,-1] #labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=None) \n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "#get accuracy, precision, recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test,predicted)\n",
    "precision_score = precision_score(y_test,predicted)\n",
    "recall_score = recall_score(y_test,predicted)\n",
    "print(\"Accuracy:\",accuracy_score)\n",
    "print(\"Precision:\",precision_score)\n",
    "print(\"Recall:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
