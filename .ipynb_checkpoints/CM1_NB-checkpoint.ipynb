{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch data and add headers\n",
    "filepath = 'promise_CM1.csv'\n",
    "column = [\"loc\",\"v(g)\",\"ev(g)\",\"n\",\"v\",\"l\",\"d\",\"i\",\"e\",\"b\",\"t\",\n",
    "          \"loCode\",\"loComment\",\"loBlank\",\"locCodeAndComment\",\n",
    "          \"uniq_Opnd\",\"total_Op\",\"branchCount\",\"defects\"]\n",
    "df = pd.read_csv(filepath, names=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>b</th>\n",
       "      <th>t</th>\n",
       "      <th>loCode</th>\n",
       "      <th>loComment</th>\n",
       "      <th>loBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.1</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>309.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.54</td>\n",
       "      <td>2936.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>163.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>4.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>215.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13.47</td>\n",
       "      <td>3447.89</td>\n",
       "      <td>0.07</td>\n",
       "      <td>191.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>6.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>346.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.33</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5999.58</td>\n",
       "      <td>0.12</td>\n",
       "      <td>333.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1563.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>28.00</td>\n",
       "      <td>55.85</td>\n",
       "      <td>43785.90</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2432.55</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>587.63</td>\n",
       "      <td>0.05</td>\n",
       "      <td>19.13</td>\n",
       "      <td>30.72</td>\n",
       "      <td>11241.58</td>\n",
       "      <td>0.20</td>\n",
       "      <td>624.53</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82.0</th>\n",
       "      <th>11.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>3155.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>44.71</td>\n",
       "      <td>70.59</td>\n",
       "      <td>141084.24</td>\n",
       "      <td>1.05</td>\n",
       "      <td>7838.01</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>150.41</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.50</td>\n",
       "      <td>23.14</td>\n",
       "      <td>977.69</td>\n",
       "      <td>0.05</td>\n",
       "      <td>54.32</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>564.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.09</td>\n",
       "      <td>35.08</td>\n",
       "      <td>9078.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>504.35</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                loc   v(g)    ev(g)     n      v      l          d     i  \\\n",
       "1.1  1.4  1.4   1.4    1.3     1.30  1.30   1.30   1.30       1.30  1.30   \n",
       "1.0  1.0  1.0   1.0    1.0     1.00  1.00   1.00   1.00       1.00  1.00   \n",
       "24.0 5.0  1.0   3.0   63.0   309.13  0.11   9.50  32.54    2936.77  0.10   \n",
       "20.0 4.0  4.0   2.0   47.0   215.49  0.06  16.00  13.47    3447.89  0.07   \n",
       "24.0 6.0  6.0   2.0   72.0   346.13  0.06  17.33  19.97    5999.58  0.12   \n",
       "...             ...    ...      ...   ...    ...    ...        ...   ...   \n",
       "47.0 3.0  1.0   3.0  256.0  1563.78  0.04  28.00  55.85   43785.90  0.52   \n",
       "24.0 4.0  3.0   3.0  107.0   587.63  0.05  19.13  30.72   11241.58  0.20   \n",
       "82.0 11.0 3.0  10.0  475.0  3155.83  0.02  44.71  70.59  141084.24  1.05   \n",
       "10.0 2.0  1.0   1.0   32.0   150.41  0.15   6.50  23.14     977.69  0.05   \n",
       "28.0 6.0  5.0   5.0  104.0   564.33  0.06  16.09  35.08    9078.38  0.19   \n",
       "\n",
       "                     e  b   t  loCode  loComment  loBlank  locCodeAndComment  \\\n",
       "1.1  1.4  1.4     1.30  2   2       2          2      1.2                1.2   \n",
       "1.0  1.0  1.0     1.00  1   1       1          1      1.0                1.0   \n",
       "24.0 5.0  1.0   163.15  1   0       6          0     15.0               15.0   \n",
       "20.0 4.0  4.0   191.55  0   0       3          0     16.0                8.0   \n",
       "24.0 6.0  6.0   333.31  0   0       3          0     16.0               12.0   \n",
       "...                ... ..  ..     ...        ...      ...                ...   \n",
       "47.0 3.0  1.0  2432.55  2  13       2          0     23.0               46.0   \n",
       "24.0 4.0  3.0   624.53  1   7       4          0     22.0               23.0   \n",
       "82.0 11.0 3.0  7838.01  9  59      35          0     32.0               68.0   \n",
       "10.0 2.0  1.0    54.32  1  12       4          0     13.0               13.0   \n",
       "28.0 6.0  5.0   504.35  2   7       0          0     20.0               23.0   \n",
       "\n",
       "               uniq_Opnd  total_Op  branchCount  defects  \n",
       "1.1  1.4  1.4        1.2       1.2          1.4    False  \n",
       "1.0  1.0  1.0        1.0       1.0          1.0     True  \n",
       "24.0 5.0  1.0       44.0      19.0          9.0    False  \n",
       "20.0 4.0  4.0       31.0      16.0          7.0    False  \n",
       "24.0 6.0  6.0       46.0      26.0         11.0    False  \n",
       "...                  ...       ...          ...      ...  \n",
       "47.0 3.0  1.0      144.0     112.0          5.0     True  \n",
       "24.0 4.0  3.0       67.0      40.0          7.0     True  \n",
       "82.0 11.0 3.0      285.0     190.0         21.0     True  \n",
       "10.0 2.0  1.0       19.0      13.0          3.0     True  \n",
       "28.0 6.0  5.0       67.0      37.0         11.0     True  \n",
       "\n",
       "[498 rows x 19 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 498 entries, (1.1, 1.4, 1.4) to (28.0, 6.0, 5.0)\n",
      "Data columns (total 19 columns):\n",
      "loc                  498 non-null float64\n",
      "v(g)                 498 non-null float64\n",
      "ev(g)                498 non-null float64\n",
      "n                    498 non-null float64\n",
      "v                    498 non-null float64\n",
      "l                    498 non-null float64\n",
      "d                    498 non-null float64\n",
      "i                    498 non-null float64\n",
      "e                    498 non-null float64\n",
      "b                    498 non-null int64\n",
      "t                    498 non-null int64\n",
      "loCode               498 non-null int64\n",
      "loComment            498 non-null int64\n",
      "loBlank              498 non-null float64\n",
      "locCodeAndComment    498 non-null float64\n",
      "uniq_Opnd            498 non-null float64\n",
      "total_Op             498 non-null float64\n",
      "branchCount          498 non-null float64\n",
      "defects              498 non-null bool\n",
      "dtypes: bool(1), float64(14), int64(4)\n",
      "memory usage: 73.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1] #features\n",
    "y = df.iloc[:,-1] #labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for Gausian NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict model on test data\n",
    "predicted = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8484848484848485\n",
      "Precision: 0.18181818181818182\n",
      "Recall: 0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "#get accuracy, precision, recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test,predicted)\n",
    "precision_score = precision_score(y_test,predicted)\n",
    "recall_score = recall_score(y_test,predicted)\n",
    "print(\"Accuracy:\",accuracy_score)\n",
    "print(\"Precision:\",precision_score)\n",
    "print(\"Recall:\",recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPROACH 2 - split data - separate columns into features and labels, then split as 70:30\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df, defect_encoded, test_size=0.3, random_state=int(time.time()))\n",
    "\n",
    "#k-fold\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train, X_test = df.iloc[:,0:-1], df.iloc[:,0:-1]\n",
    "    y_train, y_test = df.iloc[:,-1], df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.857429718875502\n",
      "Precision: 0.28846153846153844\n",
      "Recall: 0.30612244897959184\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gnb2 = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "pred = gnb2.predict(X_test)\n",
    "\n",
    "#get accuracy, precision, recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test,pred)\n",
    "precision_score = precision_score(y_test,pred)\n",
    "recall_score = recall_score(y_test,pred)\n",
    "print(\"Accuracy:\",accuracy_score)\n",
    "print(\"Precision:\",precision_score)\n",
    "print(\"Recall:\",recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              metrics       defects\n",
      "6                   d  2.452055e+06\n",
      "8                   e  1.362269e+05\n",
      "2               ev(g)  6.738725e+04\n",
      "1                v(g)  7.729164e+03\n",
      "15          uniq_Opnd  4.690829e+03\n",
      "16           total_Op  3.040284e+03\n",
      "10                  t  2.454622e+03\n",
      "14  locCodeAndComment  1.537476e+03\n",
      "5                   l  1.268298e+03\n",
      "11             loCode  5.181270e+02\n"
     ]
    }
   ],
   "source": [
    "#APPROACH 3 - FEATURE SELECTION (Univariate Selection)\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X = df.iloc[:,0:-1] #features\n",
    "y = df.iloc[:,-1] #labels\n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['metrics','defects']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'defects'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06259923 0.0394523  0.07238066 0.05594926 0.05831236 0.05539049\n",
      " 0.05028177 0.05252149 0.03815066 0.05959854 0.09225545 0.06625275\n",
      " 0.00380878 0.0579627  0.07181476 0.05144822 0.05619707 0.05562353]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ccbd320>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#APPROACH 3 - FEATURE SELECTION (Feature Importance)\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# features = [\"v(g)\",\"l\",\"d\",\"i\",\"e\",\"b\",\n",
    "#            \"loCode\",\"loComment\",\"loBlank\",\"uniq_Op\"]\n",
    "\n",
    "# #features = [\"e\",\"t\",\"v\",\"n\",\"total_Op\",\"total_Opnd\",\"loComment\",\"loc\",\"uniq_Opnd\",\"i\"]\n",
    "\n",
    "# X = df[features] #features\n",
    "# y = df.iloc[:,-1]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# gnb = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get accuracy, precision, recall\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "\n",
    "# accuracy_score = accuracy_score(y_test,predicted)\n",
    "# precision_score = precision_score(y_test,predicted)\n",
    "# recall_score = recall_score(y_test,predicted)\n",
    "# print(\"Accuracy:\",accuracy_score)\n",
    "# print(\"Precision:\",precision_score)\n",
    "# print(\"Recall:\",recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_train)\n",
    "len(X_train.columns[constant_filter.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((333, 18), (165, 18))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = constant_filter.transform(X_train)\n",
    "X_test = constant_filter.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.727e+02 7.729e+03 6.739e+04 1.515e+00 2.087e+02 1.268e+03 2.452e+06\n",
      " 2.420e+01 1.362e+05 3.771e+01 2.455e+03 5.181e+02 1.867e+00 1.879e+02\n",
      " 1.537e+03 4.691e+03 3.040e+03 3.477e+02]\n",
      "[[1.300e+00 1.300e+00 1.300e+00 1.300e+00]\n",
      " [1.000e+00 1.000e+00 1.000e+00 1.000e+00]\n",
      " [6.300e+01 3.091e+02 2.937e+03 1.632e+02]\n",
      " [4.700e+01 2.155e+02 3.448e+03 1.916e+02]\n",
      " [7.200e+01 3.461e+02 6.000e+03 3.333e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Chi-Squared statistical test\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, y)\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "\n",
    "features = fit.transform(X)\n",
    "# Summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n"
     ]
    }
   ],
   "source": [
    "# Import your necessary dependencies\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, y)\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exhaustive feature selection\n",
    "#train_features, test_features, train_labels, test_labels\n",
    "#X_train, X_test, y_train, y_test\n",
    "import numpy as np\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "feature_selector = ExhaustiveFeatureSelector(RandomForestClassifier(n_jobs=-1),\n",
    "           min_features=2,\n",
    "           max_features=5,\n",
    "           #scoring='roc_auc',\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_selector.fit(np.array(X_train.fillna(0)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_features= X_train.columns[list(features.k_feature_idx_)]\n",
    "filtered_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=41, max_depth=3)\n",
    "clf.fit(X_train[filtered_features].fillna(0), y_test)\n",
    "\n",
    "train_pred = clf.predict_proba(X_train[filtered_features].fillna(0))\n",
    "print('Accuracy on training set: {}'.format(roc_auc_score(y_test, train_pred[:,1])))\n",
    "\n",
    "test_pred = clf.predict_proba(X_test[filtered_features].fillna(0))\n",
    "print('Accuracy on test set: {}'.format(roc_auc_score(y_test, test_pred [:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True False  True  True  True  True False  True False\n",
      "  True  True  True  True  True  True]\n",
      "[1 1 3 1 4 1 1 1 1 2 1 5 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 14)\n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 14\n",
      "Score with 14 features: 0.161023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/Users/sanika/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,20)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
