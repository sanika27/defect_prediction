{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#Create lists to update the scores\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "#Columns to read from Python_01 dataset\n",
    "p1 = ['complexity','token_count','loc','comments',\n",
    "    'multi','blank','code_comment','h1','h2','N1','N2','vocabulary','length',\n",
    "    'calculated_length','volume', 'difficulty','effort','time','bugs','defect'] \n",
    "\n",
    "#Columns to read from Python_02 dataset\n",
    "p2 = ['complexity','token_count','loc','comments',\n",
    "          'multi','blank','code_comment','h1','h2','N1','N2','vocabulary','length',\n",
    "          'calculated_length','volume', 'difficulty','effort','time','bugs',\n",
    "          'change_type','added','removed','defect'] \n",
    "\n",
    "#Columns to read from Python_03 dataset\n",
    "p3 = ['complexity','token_count','loc','comments',\n",
    "          'multi','blank','code_comment','h1','h2','N1','N2','vocabulary','length',\n",
    "          'calculated_length','volume', 'difficulty','effort','time','bugs','change_type','added','removed',\n",
    "          'introspection','object_changes','code_generation','library_loading','defect']\n",
    "\n",
    "#Columns to read from CM1 dataset\n",
    "c1 = ['loc','v(g)','n','v','l','d','i',\n",
    "       'e','b','t','lOCode','lOComment','lOBlank','locCodeAndComment',\n",
    "       'uniq_Op','uniq_Opnd','total_Op','total_Opnd',\n",
    "       'branchCount','defects']\n",
    "\n",
    "#Columns to read from KC3 dataset\n",
    "k3 = [\"loc_blank\",\"loc_code_and_comment\",\n",
    "          \"loc_comments\",\"cyclomatic_complexity\",\n",
    "          \"loc_executable\",\"halstead_content\",\"halstead_difficulty\",\"halstead_effort\",\"halstead_error_est\",\n",
    "         \"halstead_length\",\"halstead_level\",\"halstead_prog_time\",\"halstead_volumn\",\"num_operands\",\"num_operators\",\n",
    "          \"num_unique_operands\",\"num_unique_operators\",\"number_of_lines\",\"loc_total\",\"defects\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to perform classification algorithms\n",
    "def nb_func(df,algo):\n",
    "    X = df.iloc[:,0:-1] #features\n",
    "    y = df.iloc[:,-1] #labels\n",
    "    clf = algo #get the algorithm\n",
    "\n",
    "##Apply selectKBest for 10 best features\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "    bestfit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(bestfit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['feature','score']\n",
    "    ten = featureScores.nlargest(10,'score')\n",
    "    ten_df = pd.DataFrame(ten)\n",
    "    ten.plot(kind='bar')\n",
    "    plt.show()\n",
    "    \n",
    "    kfold = RepeatedKFold(n_splits=10, n_repeats=5, random_state=None)\n",
    "    for train_ix, test_ix in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "# #Predict the response for test dataset\n",
    "        predicted_cv = clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test,predicted_cv))\n",
    "        precision.append(precision_score(y_test,predicted_cv))\n",
    "        recall.append(recall_score(y_test,predicted_cv))\n",
    "    print(confusion_matrix(y_test,predicted_cv))\n",
    "    evaluation_func(accuracy, precision, recall)\n",
    "    \n",
    "##Evaluation Function\n",
    "def evaluation_func(accuracy, precision, recall):\n",
    "    print(\"ACCURACY\")\n",
    "    mean_acc = np.mean(accuracy)\n",
    "    print(\"Mean :\",mean_acc)\n",
    "#     max_acc = np.max(accuracy)\n",
    "#     print(\"Max :\",max_acc)\n",
    "\n",
    "    print(\"PRECISION\")\n",
    "    mean_precision = np.mean(precision)\n",
    "    print(\"Mean :\",mean_precision)\n",
    "#     max_precision = np.max(precision)\n",
    "#     print(\"Max :\",max_precision)\n",
    "\n",
    "    print(\"RECALL\")\n",
    "    mean_recall = np.mean(recall)\n",
    "    print(\"Mean :\",mean_recall)\n",
    "#     max_recall = np.max(recall)\n",
    "#     print(\"Max :\",max_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the different datasets by calling the function which needs dataset and algorithm to be passed as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read python_01 dataset\n",
    "filepath = 'python_01.csv'\n",
    "python_01 = pd.read_csv(filepath, index_col=None, usecols= p1)\n",
    "\n",
    "#Pass an algorithm to execute (like example below)\n",
    "\n",
    "algo = DecisionTreeClassifier() \n",
    "#algo = GaussianNB()                             \n",
    "#algo = svm.SVC(gamma='auto') \n",
    "#algo = MLPClassifier(hidden_layer_sizes=(150,80),max_iter=200,activation = 'relu',solver='adam',random_state=50)\n",
    "\n",
    "nb_func(python_01,algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read python_02 dataset\n",
    "filepath = 'python_02.csv'\n",
    "python_02 = pd.read_csv(filepath, index_col=None, usecols= p2)\n",
    "\n",
    "#Pass an algorithm to execute (like example below)\n",
    "\n",
    "algo = DecisionTreeClassifier() \n",
    "#algo = GaussianNB()                             \n",
    "#algo = svm.SVC(gamma='auto') \n",
    "#algo = MLPClassifier(hidden_layer_sizes=(150,80),max_iter=200,activation = 'relu',solver='adam',random_state=50)\n",
    "\n",
    "nb_func(python_02,algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read python_03 dataset\n",
    "filepath = 'python_03.csv'\n",
    "python_03 = pd.read_csv(filepath, index_col=None, usecols= p3)\n",
    "\n",
    "#Pass an algorithm to execute (like example below)\n",
    "\n",
    "algo = DecisionTreeClassifier() \n",
    "#algo = GaussianNB()                             \n",
    "#algo = svm.SVC(gamma='auto') \n",
    "#algo = MLPClassifier(hidden_layer_sizes=(150,80),max_iter=200,activation = 'relu',solver='adam',random_state=50)\n",
    "\n",
    "nb_func(python_03,algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CM1 dataset\n",
    "filepath = 'promise_CM1.csv'\n",
    "cm1 = pd.read_csv(filepath, index_col=None, usecols= c1)\n",
    "\n",
    "#Pass an algorithm to execute (like example below)\n",
    "\n",
    "algo = DecisionTreeClassifier() \n",
    "#algo = GaussianNB()                             \n",
    "#algo = svm.SVC(gamma='auto') \n",
    "#algo = MLPClassifier(hidden_layer_sizes=(150,80),max_iter=200,activation = 'relu',solver='adam',random_state=50)\n",
    "\n",
    "nb_func(cm1,algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read KC3 dataset\n",
    "filepath = 'promise_KC3.csv'\n",
    "kc3 = pd.read_csv(filepath, index_col=None, usecols= k3)\n",
    "\n",
    "#Pass an algorithm to execute (like example below)\n",
    "\n",
    "algo = DecisionTreeClassifier() \n",
    "#algo = GaussianNB()                             \n",
    "#algo = svm.SVC(gamma='auto') \n",
    "#algo = MLPClassifier(hidden_layer_sizes=(150,80),max_iter=200,activation = 'relu',solver='adam',random_state=50)\n",
    "\n",
    "nb_func(kc3,algo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
