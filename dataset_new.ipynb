{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import csv\n",
    "# from pydriller import RepositoryMining\n",
    "# from radon.raw import analyze\n",
    "# from radon.metrics import h_visit\n",
    "# from radon.metrics import h_visit_ast\n",
    "# from radon.complexity import sorted_results\n",
    "# from pydriller.git_repository import GitRepository\n",
    "\n",
    "# fields = ['CommitID','filename','loc','lloc','sloc','comments','multi','blank','code_comment','h1',\n",
    "#          'h2','N1','N2','vocabulary','length','calculated_length','volume',                     \n",
    "#          'difficulty','effort','time','bugs']\n",
    "# releases = ['4.6.6','4.6.7','4.6.8','4.6.9','5.3.0','5.3.1','5.3.2','5.3.3','5.3.4','5.3.5']\n",
    "# repo = \"/Users/sanika/Downloads/Master Thesis/repo_updated/pytest\"\n",
    "\n",
    "# # count = 0\n",
    "# i = 0\n",
    "# length = len(releases)-1\n",
    "# while i < length:\n",
    "#     for commit in RepositoryMining(repo,\n",
    "#                                    only_modifications_with_file_types=['.py'],\n",
    "#                                    from_tag=releases[i],\n",
    "#                                    to_tag=releases[i+1]).traverse_commits():\n",
    "#         for modification in commit.modifications:\n",
    "# #             date = commit.committer_date\n",
    "#             mod_file = modification.filename\n",
    "#             hash_val = commit.hash\n",
    "#             i += 1\n",
    "#             with open('extracted_data_000.csv', 'w') as csvFile:\n",
    "#                 writer = csv.DictWriter(csvFile, fieldnames = fields)\n",
    "#                 writer.writeheader()\n",
    "#                 for filename in mod_file: #files:\n",
    "#                     if filename.endswith(\".py\"):\n",
    "#                         print(filename)\n",
    "#                         with open(filename) as f:\n",
    "#                             content = f.read()\n",
    "#                             file_analyze = analyze(content) #raw metrics\n",
    "#                             code_n_comment = file_analyze.loc+file_analyze.comments\n",
    "#                             file_ast = h_visit(content) #Compile the code into an AST tree\n",
    "#                             count = count + 1\n",
    "#                             data = [{'CommitID':(hash_val),\n",
    "#                                      'filename':(mod_file),\n",
    "#                                      'loc':(file_analyze.loc),\n",
    "#                                      'lloc':(file_analyze.lloc),\n",
    "#                                      'sloc':(file_analyze.sloc),\n",
    "#                                      'comments':(file_analyze.comments),\n",
    "#                                      'multi':(file_analyze.multi),\n",
    "#                                      'blank':(file_analyze.blank),\n",
    "#                                      'code_comment':(code_n_comment),\n",
    "#                                      'h1':(file_ast.total.h1),\n",
    "#                                      'h2':(file_ast.total.h2),\n",
    "#                                      'N1':(file_ast.total.N1),\n",
    "#                                      'N2':(file_ast.total.N2),\n",
    "#                                      'vocabulary':(file_ast.total.vocabulary),\n",
    "#                                      'length':(file_ast.total.length),\n",
    "#                                      'calculated_length':(file_ast.total.calculated_length),\n",
    "#                                      'volume':(file_ast.total.volume),                     \n",
    "#                                      'difficulty':(file_ast.total.difficulty),\n",
    "#                                      'effort':(file_ast.total.effort),\n",
    "#                                      'time':(file_ast.total.time),\n",
    "#                                      'bugs':(file_ast.total.bugs),}]\n",
    "#                             writer.writerows(data)\n",
    "\n",
    "# print(\"writing completed\")\n",
    "# csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing completed\n"
     ]
    }
   ],
   "source": [
    "#extract data with release filter\n",
    "import os\n",
    "import csv\n",
    "from pydriller import RepositoryMining\n",
    "from radon.raw import analyze\n",
    "from radon.metrics import h_visit\n",
    "from radon.metrics import h_visit_ast\n",
    "from radon.complexity import sorted_results\n",
    "from pydriller.git_repository import GitRepository\n",
    "\n",
    "fields = ['CommitID','filename','token_count','change_type','loc','lloc','sloc','comments',\n",
    "          'multi','blank','code_comment','h1','h2','N1','N2','vocabulary','length',\n",
    "          'calculated_length','volume', 'difficulty','effort','time','bugs']\n",
    "# 'change_type','lines_added','lines_removed',\n",
    "releases = ['4.6.6','4.6.7','4.6.8','4.6.9','5.3.0','5.3.1','5.3.2','5.3.3','5.3.4','5.3.5']\n",
    "repo_updated = \"/Users/sanika/Downloads/Master Thesis/repo_updated/pytest\"\n",
    "    \n",
    "# gitrepo = GitRepository(\"/Users/sanika/Downloads/Master Thesis/repo_updated/pytest\")\n",
    "# gitfiles = gitrepo.files()\n",
    "# no_commits = gitrepo.total_commits() #total number of commits\n",
    "\n",
    "count = 0\n",
    "i = 0\n",
    "length = len(releases)-1\n",
    "\n",
    "with open('extracted_data_000.csv', 'w') as csvFile:\n",
    "    writer = csv.DictWriter(csvFile, fieldnames = fields)\n",
    "    writer.writeheader()\n",
    "    while i < length:\n",
    "        from_tag=releases[i]\n",
    "        to_tag=releases[i+1]\n",
    "        i += 1\n",
    "        for commit in RepositoryMining(repo_updated,\n",
    "                                   only_modifications_with_file_types=['.py'],\n",
    "                                   from_tag=from_tag,\n",
    "                                   to_tag=to_tag).traverse_commits():\n",
    "            for modification in commit.modifications:\n",
    "                filename = modification.filename\n",
    "                hash_val = commit.hash\n",
    "                change_type = modification.change_type\n",
    "                token_count = modification.token_count\n",
    "#                 added = modification.added\n",
    "#                 removed = modification.removed\n",
    "                if filename.endswith(\".py\"):\n",
    "                    for r, d, f in os.walk(repo_updated):\n",
    "                        for file in f:\n",
    "                            if filename in file:\n",
    "                                file_path = os.path.join(r, file)\n",
    "                                with open(file_path) as f:\n",
    "                                    content = f.read()\n",
    "                                    file_analyze = analyze(content)\n",
    "                                    code_n_comment = file_analyze.loc+file_analyze.comments\n",
    "                                    file_ast = h_visit(content)\n",
    "                                    data = [{'CommitID':(hash_val), #put to a dataframe\n",
    "                                     'filename':(file_path),\n",
    "                                     'token_count':(token_count),\n",
    "                                     'change_type':(change_type),\n",
    "#                                      'lines_added':(added),\n",
    "#                                      'lines_removed':(removed),\n",
    "                                     'loc':(file_analyze.loc),\n",
    "                                     'lloc':(file_analyze.lloc),\n",
    "                                     'sloc':(file_analyze.sloc),\n",
    "                                     'commeants':(file_analyze.comments),\n",
    "                                     'multi':(file_analyze.multi),\n",
    "                                     'blank':(file_analyze.blank),\n",
    "                                     'code_comment':(code_n_comment),\n",
    "                                     'h1':(file_ast.total.h1),\n",
    "                                     'h2':(file_ast.total.h2),\n",
    "                                     'N1':(file_ast.total.N1),\n",
    "                                     'N2':(file_ast.total.N2),\n",
    "                                     'vocabulary':(file_ast.total.vocabulary),\n",
    "                                     'length':(file_ast.total.length),\n",
    "                                     'calculated_length':(file_ast.total.calculated_length),\n",
    "                                     'volume':(file_ast.total.volume),                     \n",
    "                                     'difficulty':(file_ast.total.difficulty),\n",
    "                                     'effort':(file_ast.total.effort),\n",
    "                                     'time':(file_ast.total.time),\n",
    "                                     'bugs':(file_ast.total.bugs),}]\n",
    "                                    writer.writerows(data) # saving the dataframe => df.to_csv('file1.csv') \n",
    "                                    i += 1\n",
    "print(\"writing completed\")\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
